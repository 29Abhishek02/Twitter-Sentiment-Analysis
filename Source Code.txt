import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string
import nltk
import warnings
%matplotlib inline

warnings.filterwarnings('ignore')



df = pd.read_csv('twitter sentiments set.csv')
df.head()



# datatype info
df.info()



# removes pattern in the input text
def remove_pattern(input_txt, pattern):
    r = re.findall(pattern, input_txt)
    for word in r:
        input_txt = re.sub(word, "", input_txt)
    return input_txt
df.head()



# remove twitter handles (@user)
df['clean_tweet'] = np.vectorize(remove_pattern)(df['tweet'], "@[\w]*")
df.head()



# remove special characters, numbers and punctuations
df['clean_tweet'] = df['clean_tweet'].str.replace("[^a-zA-Z#]", " ")
df.head()



# remove short words
df['clean_tweet'] = df['clean_tweet'].apply(lambda x: " ".join([w for w in x.split() if len(w)>3]))
df.head()



# individual words considered as tokens
tokenized_tweet = df['clean_tweet'].apply(lambda x: x.split())
tokenized_tweet.head()



# stem the words
from nltk.stem.porter import PorterStemmer
stemmer = PorterStemmer()
tokenized_tweet = tokenized_tweet.apply(lambda sentence: [stemmer.stem(word) for word in sentence])
tokenized_tweet.head()



# combine words into single sentence
for i in range(len(tokenized_tweet)):
    tokenized_tweet[i] = " ".join(tokenized_tweet[i])
    
df['clean_tweet'] = tokenized_tweet
df.head()



# visualize the frequent words
all_words = " ".join([sentence for sentence in df['clean_tweet']])

from wordcloud import WordCloud
wordcloud = WordCloud(width=900, height=500, random_state=42, max_font_size=50).generate(all_words)

# plot the graph
plt.figure(figsize=(15,8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()



# frequent words visualization for +ve
all_words = " ".join([sentence for sentence in df['clean_tweet'][df['label']==0]])

wordcloud = WordCloud(width=900, height=500, random_state=42, max_font_size=50).generate(all_words)

# plot the graph
plt.figure(figsize=(15,8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()



# frequent words visualization for -ve
all_words = " ".join([sentence for sentence in df['clean_tweet'][df['label']==1]])

wordcloud = WordCloud(width=900, height=500, random_state=42, max_font_size=50).generate(all_words)

# plot the graph
plt.figure(figsize=(15,8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()



# extract the hashtag
def hashtag_extract(tweets):
    hashtags = []
    # loop words in the tweet
    for tweet in tweets:
        ht = re.findall(r"#(\w+)", tweet)
        hashtags.append(ht)
    return hashtags



# extract hashtags from non-racist/sexist tweets
ht_positive = hashtag_extract(df['clean_tweet'][df['label']==0])
# extract hashtags from racist/sexist tweets
ht_negative = hashtag_extract(df['clean_tweet'][df['label']==1])



ht_positive[:7]
# unnest list
ht_positive = sum(ht_positive, [])
ht_negative = sum(ht_negative, [])
ht_positive[:7]
freq = nltk.FreqDist(ht_positive)
d = pd.DataFrame({'Hashtag': list(freq.keys()),
                  'Count': list(freq.values())})
d.head()



freq = nltk.FreqDist(ht_positive)
d = pd.DataFrame({'Hashtag': list(freq.keys()),
                  'Count': list(freq.values())})
d = d.nlargest(columns='Count', n=15)
colors = ['red', 'orange', 'yellow', 'green', 'blue', 'purple', 'pink', 'brown', 'gray', 'black']
plt.figure(figsize=(12, 8))
plt.barh(y=d['Hashtag'], width=d['Count'], color=colors)
plt.title('Top Hashtags in Positive Tweets')
plt.xlabel('Count')
plt.ylabel('Hashtag')
plt.show()



freq = nltk.FreqDist(ht_negative)
d = pd.DataFrame({'Hashtag': list(freq.keys()),
                  'Count': list(freq.values())})
d.head()



freq = nltk.FreqDist(ht_negative)
d = pd.DataFrame({'Hashtag': list(freq.keys()),
                  'Count': list(freq.values())})
d = d.nlargest(columns='Count', n=15)
plt.figure(figsize=(12, 8))
colors = ['purple', 'pink', 'yellow', 'black', 'gray', 'red', 'orange', 'brown', 'blue', 'green']
plt.barh(y=d['Hashtag'], width=d['Count'], color=colors)
plt.title('Top Hashtags in Negative Tweets')
plt.xlabel('Count')
plt.ylabel('Hashtag')
plt.show()



df['length'] = df['clean_tweet'].apply(len)
plt.figure(figsize=(15, 8))
sns.boxplot(x='label', y='length', data=df)
plt.title('Tweet Length Distribution')
plt.xlabel('Sentiment')
plt.ylabel('Tweet Length')
plt.show()



# Logistic Regression
# feature extraction
from sklearn.feature_extraction.text import CountVectorizer
bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')
bow = bow_vectorizer.fit_transform(df['clean_tweet'])


from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, precision_score

# Split the dataset into training and testing sets
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(bow, df['label'], random_state=42, test_size=0.25)

# Create a Logistic Regression model
model = LogisticRegression(random_state=42)

# Train the model on the training data
model.fit(x_train, y_train)

# Make predictions on the test data
pred_prob = model.predict_proba(x_test)
pred = pred_prob[:, 1] >= 0.3
pred = pred.astype(np.int64)

# Evaluate the model's performance using F1-score, accuracy, and precision
f1_score_lr = f1_score(y_test, pred)
accuracy_lr = accuracy_score(y_test, pred)
precision_lr = precision_score(y_test, pred)

print("Logistic Regression F1-score:", f1_score_lr)
print("Logistic Regression Accuracy:", accuracy_lr)
print("Logistic Regression Precision:", precision_lr)



pred_prob[0][1] >= 0.3



# RandomForestClassifier

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score

# Split the dataset into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(bow, df['label'], random_state=42, test_size=0.25)

# Create a Random Forests model
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model on the training data
model.fit(x_train, y_train)

# Make predictions on the test data
pred = model.predict(x_test)

# Evaluate the model's performance using F1-score and accuracy
f1_score_rf = f1_score(y_test, pred)
accuracy_rf = accuracy_score(y_test, pred)
precision_rf = precision_score(y_test, pred)

print("Random Forests F1-score:", f1_score_rf)
print("Random Forests Accuracy:", accuracy_rf)
print("Random Forests Precision:", precision_rf)



from sklearn.metrics import roc_curve, auc

# Get predicted probabilities for the test data
probs = model.predict_proba(x_test)[:, 1]

# Calculate the false positive rate, true positive rate, and threshold values for different threshold values
fpr, tpr, thresholds = roc_curve(y_test, probs)

# Calculate the area under the ROC curve
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.show()



results_lr = pd.DataFrame({
    'F1-score':[f1_score_lr],
    'Accuracy':[accuracy_lr],
    'Precision':[precision_lr]
}, index=['Logistic Regression'])

results_rf = pd.DataFrame({
    'F1-score': [f1_score_rf],
    'Accuracy':[accuracy_rf],
    'Precision':[precision_rf]
}, index=['Random Forest'])

# Set the index name to 'Algorithm'
results_lr.index.name = 'Algorithm'
results_rf.index.name = 'Algorithm'

# Combine both data frames into one for easier plotting
results = pd.concat([results_lr, results_rf])

# Plot the box plots
results.boxplot(column=['F1-score', 'Accuracy', 'Precision'], figsize=(10, 6))
plt.title('Comparison of Evaluation Metrics')
plt.ylabel('Score')
plt.show()




# Support Vector Machine (SVM)
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, f1_score, precision_score

# Vectorize tweets using Bag of Words model
from sklearn.feature_extraction.text import CountVectorizer
bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1, 3), analyzer = "word")
bow.fit(df['clean_tweet'])
x = bow.transform(df['clean_tweet'])

# Fit the SVM model
model = SVC(kernel='linear', probability=True, random_state=42)
model.fit(x_train, y_train)

# Make predictions on the test set and calculate performance metrics
pred = model.predict(x_test)
f1_score_svm = f1_score(y_test, pred)
accuracy_svm = accuracy_score(y_test,pred)
precision_svm = precision_score(y_test, pred)

print("SVM Model Performance:")
print("F1 Score: ", f1_score_svm)
print("Accuracy: ", accuracy_svm)
print("Precision: ", precision_svm)



results_lr = pd.DataFrame({
    'F1-score':[f1_score_lr],
    'Accuracy':[accuracy_lr],
    'Precision':[precision_lr]
}, index=['Logistic Regression'])

results_rf = pd.DataFrame({
    'F1-score': [f1_score_rf],
    'Accuracy':[accuracy_rf],
    'Precision':[precision_rf]
}, index=['Random Forest'])

results_svm = pd.DataFrame({
    'F1-score':[f1_score_svm],
    'Accuracy':[accuracy_svm],
    'Precision':[precision_svm]
}, index=['SVM'])

# Set the index name to 'Algorithm'
results_lr.index.name = 'Algorithm'
results_rf.index.name = 'Algorithm'
results_svm.index.name = 'Algorithm'

# Combine both data frames into one for easier plotting
results = pd.concat([results_lr, results_rf, results_svm])

# Plot the box plots
results.boxplot(column=['F1-score', 'Accuracy', 'Precision'], figsize=(10, 6))
plt.title('Comparison of Evaluation Metrics')
plt.ylabel('Score')
plt.show()
